{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"spamdata.csv\",encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatÃ¥Ãs the way u feel. ThatÃ¥Ãs th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "10   ham  I'm gonna be home soon and i don't want to tal...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13   ham  I've been searching for the right words to tha...\n",
       "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16   ham                         Oh k...i'm watching here:)\n",
       "17   ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18   ham  Fine if thatÃ¥Ãs the way u feel. ThatÃ¥Ãs th...\n",
       "19  spam  England v Macedonia - dont miss the goals/team..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def _clean(text):\n",
    "    cleaned_text = text.lower()\n",
    "    \n",
    "    cleaned_text = \"\".join(c for c in text if c not in punctuations)\n",
    "    \n",
    "    words = cleaned_text.split()\n",
    "    \n",
    "    words = [w for w in words if w not in stopwords_list]\n",
    "    \n",
    "    words = [lem.lemmatize(word,\"v\") for word in words]\n",
    "    words = [lem.lemmatize(word,\"n\") for word in words]\n",
    "    \n",
    "    cleaned_text =\" \".join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cleaned\"] = data[\"text\"].apply(_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature enginering\n",
    "#meta features\n",
    "\n",
    "\n",
    "data[\"word_count\"] = data[\"text\"].apply(lambda x : len(x.split()))\n",
    "data[\"word_count_cleaned\"] = data[\"cleaned\"].apply(lambda x : len(x.split()))\n",
    "\n",
    "data[\"char_count\"] = data[\"text\"].apply(lambda x : len(x))\n",
    "data[\"char_count_without_spaces\"] = data[\"text\"].apply(lambda x : len(x.replace(\" \",\"\")))\n",
    "\n",
    "data[\"num_digit\"] = data[\"text\"].apply(lambda x : sum([1 if w.isdigit() else 0 for w in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say early hor U c already say</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think go usf live around though</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  Go jurong point crazy Available bugis n great ...          20   \n",
       "1                            Ok lar Joking wif u oni           6   \n",
       "2  Free entry 2 wkly comp win FA Cup final tkts 2...          28   \n",
       "3                U dun say early hor U c already say          11   \n",
       "4         Nah I dont think go usf live around though          13   \n",
       "\n",
       "   word_count_cleaned  char_count  char_count_without_spaces  num_digit  \n",
       "0                  16         111                         92          0  \n",
       "1                   6          29                         24          0  \n",
       "2                  23         155                        128          2  \n",
       "3                   9          49                         39          0  \n",
       "4                   9          61                         49          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dic={\"noun\":[\"NNP\",\"NN\",\"NNS\",\"NNPS\"],\"verb\":[\"VBZ\",\"VB\",\"VBD\",\"VBN\",\"VBG\"]}\n",
    "\n",
    "import nltk\n",
    "\n",
    "def pos_check(text,family):\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    count=0\n",
    "    \n",
    "    for tag in tags:\n",
    "        tag = tag[1]\n",
    "        if tag in pos_dic[family]:\n",
    "            count+=1\n",
    "    return count\n",
    "    \n",
    "#pos_check(\"i am playing in the ground\",\"noun\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"noun_count\"] = data[\"text\"].apply(lambda x : pos_check(x,\"noun\"))\n",
    "data[\"verb_count\"] = data[\"text\"].apply(lambda x : pos_check(x,\"verb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_digit</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say early hor U c already say</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think go usf live around though</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  Go jurong point crazy Available bugis n great ...          20   \n",
       "1                            Ok lar Joking wif u oni           6   \n",
       "2  Free entry 2 wkly comp win FA Cup final tkts 2...          28   \n",
       "3                U dun say early hor U c already say          11   \n",
       "4         Nah I dont think go usf live around though          13   \n",
       "\n",
       "   word_count_cleaned  char_count  char_count_without_spaces  num_digit  \\\n",
       "0                  16         111                         92          0   \n",
       "1                   6          29                         24          0   \n",
       "2                  23         155                        128          2   \n",
       "3                   9          49                         39          0   \n",
       "4                   9          61                         49          0   \n",
       "\n",
       "   noun_count  verb_count  \n",
       "0          10           1  \n",
       "1           4           0  \n",
       "2          13           3  \n",
       "3           3           0  \n",
       "4           1           4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "\n",
    "cvz = CountVectorizer()\n",
    "cvz.fit(data[\"cleaned\"].values)\n",
    "\n",
    "count_vectors = cvz.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8590 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 51048 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tfidf = TfidfVectorizer(max_features=500)\n",
    "word_tfidf.fit(data[\"cleaned\"].values)\n",
    "\n",
    "word_vectors_tfidf = word_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_tfidf = TfidfVectorizer(max_features=500,ngram_range=(1,2))\n",
    "ngram_tfidf.fit(data[\"cleaned\"].values)\n",
    "\n",
    "ngram_tfidf = ngram_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tfidf = TfidfVectorizer(max_features=500,analyzer=\"char\")\n",
    "char_tfidf.fit(data[\"cleaned\"].values)\n",
    "\n",
    "char_tfidf = char_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = dict(zip(word_tfidf.get_feature_names(),word_tfidf.idf_))\n",
    "tfidf_idf = pd.DataFrame(columns=[\"word_tfidf\"]).from_dict(tfidf,orient=\"index\")\n",
    "tfidf_idf.columns = [\"word_tfidf\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x507 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 64155 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "meta_features = ['word_count', 'word_count_cleaned',\n",
    "       'char_count', 'char_count_without_spaces', 'num_digit', 'noun_count',\n",
    "       'verb_count']\n",
    "\n",
    "feature_set1 = data[meta_features]\n",
    "\n",
    "train = hstack([word_vectors_tfidf,csr_matrix(feature_set1)],\"csr\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = data[\"label\"].values\n",
    "target = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 507)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393, 507)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770279971284996"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(train_x,train_y)\n",
    "preds = model.predict(val_x)\n",
    "accuracy_score(preds,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryavikram/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9770279971284996"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_x,train_y)\n",
    "preds = model.predict(val_x)\n",
    "accuracy_score(preds,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryavikram/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9368269921033741"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_x,train_y)\n",
    "preds = model.predict(val_x)\n",
    "accuracy_score(preds,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryavikram/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9748743718592965"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ensemble.ExtraTreesClassifier()\n",
    "model.fit(train_x,train_y)\n",
    "preds = model.predict(val_x)\n",
    "accuracy_score(preds,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_index={}\n",
    "for i, line in enumerate(open('pretrained.vec',encoding = \"utf8\")):\n",
    "    if i ==0:\n",
    "        continue\n",
    "    value = line.split()\n",
    "    embeddings_index[value[0]] = np.array(value[1:],dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(data[\"text\"])\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'to': 2,\n",
       " 'you': 3,\n",
       " 'a': 4,\n",
       " 'the': 5,\n",
       " 'u': 6,\n",
       " 'and': 7,\n",
       " 'in': 8,\n",
       " 'is': 9,\n",
       " 'me': 10,\n",
       " 'my': 11,\n",
       " 'for': 12,\n",
       " 'your': 13,\n",
       " 'it': 14,\n",
       " 'of': 15,\n",
       " 'call': 16,\n",
       " 'have': 17,\n",
       " 'on': 18,\n",
       " '2': 19,\n",
       " 'that': 20,\n",
       " 'now': 21,\n",
       " 'are': 22,\n",
       " 'so': 23,\n",
       " 'but': 24,\n",
       " 'not': 25,\n",
       " 'or': 26,\n",
       " 'do': 27,\n",
       " 'can': 28,\n",
       " 'at': 29,\n",
       " \"i'm\": 30,\n",
       " 'get': 31,\n",
       " 'be': 32,\n",
       " 'will': 33,\n",
       " 'if': 34,\n",
       " 'ur': 35,\n",
       " 'with': 36,\n",
       " 'just': 37,\n",
       " 'no': 38,\n",
       " 'we': 39,\n",
       " 'this': 40,\n",
       " 'gt': 41,\n",
       " '4': 42,\n",
       " 'lt': 43,\n",
       " 'up': 44,\n",
       " 'when': 45,\n",
       " 'ok': 46,\n",
       " 'free': 47,\n",
       " 'from': 48,\n",
       " 'how': 49,\n",
       " 'go': 50,\n",
       " 'all': 51,\n",
       " 'out': 52,\n",
       " 'what': 53,\n",
       " 'know': 54,\n",
       " 'like': 55,\n",
       " 'good': 56,\n",
       " 'then': 57,\n",
       " 'got': 58,\n",
       " 'was': 59,\n",
       " 'come': 60,\n",
       " 'its': 61,\n",
       " 'am': 62,\n",
       " 'time': 63,\n",
       " 'only': 64,\n",
       " 'day': 65,\n",
       " 'love': 66,\n",
       " 'there': 67,\n",
       " 'send': 68,\n",
       " 'he': 69,\n",
       " 'want': 70,\n",
       " 'text': 71,\n",
       " 'as': 72,\n",
       " 'txt': 73,\n",
       " 'one': 74,\n",
       " 'going': 75,\n",
       " 'by': 76,\n",
       " 'home': 77,\n",
       " \"i'll\": 78,\n",
       " 'need': 79,\n",
       " 'about': 80,\n",
       " 'r': 81,\n",
       " 'lor': 82,\n",
       " 'sorry': 83,\n",
       " 'stop': 84,\n",
       " 'still': 85,\n",
       " 'see': 86,\n",
       " 'back': 87,\n",
       " 'today': 88,\n",
       " 'n': 89,\n",
       " 'da': 90,\n",
       " 'our': 91,\n",
       " 'reply': 92,\n",
       " 'k': 93,\n",
       " 'dont': 94,\n",
       " 'she': 95,\n",
       " 'mobile': 96,\n",
       " 'take': 97,\n",
       " \"don't\": 98,\n",
       " 'tell': 99,\n",
       " 'hi': 100,\n",
       " 'new': 101,\n",
       " 'later': 102,\n",
       " 'her': 103,\n",
       " 'pls': 104,\n",
       " 'any': 105,\n",
       " 'please': 106,\n",
       " 'think': 107,\n",
       " 'been': 108,\n",
       " 'they': 109,\n",
       " 'phone': 110,\n",
       " 'here': 111,\n",
       " 'week': 112,\n",
       " 'dear': 113,\n",
       " 'did': 114,\n",
       " 'some': 115,\n",
       " 'ã\\x8c': 116,\n",
       " '1': 117,\n",
       " 'well': 118,\n",
       " 'has': 119,\n",
       " 'much': 120,\n",
       " 'great': 121,\n",
       " 'night': 122,\n",
       " 'oh': 123,\n",
       " 'claim': 124,\n",
       " 'an': 125,\n",
       " 'hope': 126,\n",
       " 'hey': 127,\n",
       " 'msg': 128,\n",
       " 'who': 129,\n",
       " 'him': 130,\n",
       " 'where': 131,\n",
       " 'd': 132,\n",
       " 'more': 133,\n",
       " 'too': 134,\n",
       " 'happy': 135,\n",
       " 'had': 136,\n",
       " 'yes': 137,\n",
       " 'make': 138,\n",
       " 'way': 139,\n",
       " 'c': 140,\n",
       " 'www': 141,\n",
       " 'work': 142,\n",
       " 'give': 143,\n",
       " 'wat': 144,\n",
       " \"it's\": 145,\n",
       " 'number': 146,\n",
       " 'e': 147,\n",
       " 'message': 148,\n",
       " 'should': 149,\n",
       " 'prize': 150,\n",
       " 'tomorrow': 151,\n",
       " 'say': 152,\n",
       " 'right': 153,\n",
       " 'already': 154,\n",
       " 'after': 155,\n",
       " 'ask': 156,\n",
       " 'cash': 157,\n",
       " 'doing': 158,\n",
       " 'said': 159,\n",
       " '3': 160,\n",
       " 'yeah': 161,\n",
       " 'really': 162,\n",
       " 'amp': 163,\n",
       " 'why': 164,\n",
       " 'im': 165,\n",
       " 'meet': 166,\n",
       " 'them': 167,\n",
       " 'life': 168,\n",
       " 'find': 169,\n",
       " 'very': 170,\n",
       " 'morning': 171,\n",
       " 'babe': 172,\n",
       " 'last': 173,\n",
       " 'miss': 174,\n",
       " 'thanks': 175,\n",
       " 'would': 176,\n",
       " 'cos': 177,\n",
       " 'win': 178,\n",
       " 't': 179,\n",
       " 'lol': 180,\n",
       " 'also': 181,\n",
       " 'won': 182,\n",
       " 'let': 183,\n",
       " 'b': 184,\n",
       " 'anything': 185,\n",
       " 'every': 186,\n",
       " '150p': 187,\n",
       " 'com': 188,\n",
       " 'sure': 189,\n",
       " 'pick': 190,\n",
       " 'care': 191,\n",
       " 'urgent': 192,\n",
       " 'nokia': 193,\n",
       " 'sent': 194,\n",
       " 'keep': 195,\n",
       " 'over': 196,\n",
       " 'uk': 197,\n",
       " 'something': 198,\n",
       " 'contact': 199,\n",
       " 'us': 200,\n",
       " 'again': 201,\n",
       " 'buy': 202,\n",
       " 'min': 203,\n",
       " 'wait': 204,\n",
       " 'cant': 205,\n",
       " 'before': 206,\n",
       " \"i've\": 207,\n",
       " 'first': 208,\n",
       " 's': 209,\n",
       " '5': 210,\n",
       " 'even': 211,\n",
       " 'next': 212,\n",
       " 'feel': 213,\n",
       " 'were': 214,\n",
       " 'nice': 215,\n",
       " 'went': 216,\n",
       " 'thing': 217,\n",
       " 'around': 218,\n",
       " 'soon': 219,\n",
       " 'his': 220,\n",
       " 'which': 221,\n",
       " 'someone': 222,\n",
       " \"can't\": 223,\n",
       " 'could': 224,\n",
       " 'place': 225,\n",
       " 'money': 226,\n",
       " 'service': 227,\n",
       " 'off': 228,\n",
       " 'tone': 229,\n",
       " '50': 230,\n",
       " 'tonight': 231,\n",
       " 'late': 232,\n",
       " 'many': 233,\n",
       " 'per': 234,\n",
       " 'customer': 235,\n",
       " 'gonna': 236,\n",
       " 'chat': 237,\n",
       " 'ya': 238,\n",
       " 'sleep': 239,\n",
       " 'always': 240,\n",
       " 'leave': 241,\n",
       " 'co': 242,\n",
       " 'down': 243,\n",
       " 'sms': 244,\n",
       " 'dun': 245,\n",
       " 'friends': 246,\n",
       " 'v': 247,\n",
       " \"that's\": 248,\n",
       " 'gud': 249,\n",
       " 'other': 250,\n",
       " 'wan': 251,\n",
       " 'help': 252,\n",
       " 'x': 253,\n",
       " 'things': 254,\n",
       " 'told': 255,\n",
       " 'wish': 256,\n",
       " 'hello': 257,\n",
       " 'waiting': 258,\n",
       " '16': 259,\n",
       " 'ã\\x8cã\\x8f': 260,\n",
       " 'fine': 261,\n",
       " 'special': 262,\n",
       " '18': 263,\n",
       " \"you're\": 264,\n",
       " 'haha': 265,\n",
       " 'coming': 266,\n",
       " 'may': 267,\n",
       " 'name': 268,\n",
       " 'getting': 269,\n",
       " 'done': 270,\n",
       " 'year': 271,\n",
       " 'same': 272,\n",
       " 'guaranteed': 273,\n",
       " 'yet': 274,\n",
       " 'people': 275,\n",
       " 'thk': 276,\n",
       " 'use': 277,\n",
       " 'try': 278,\n",
       " 'friend': 279,\n",
       " 'mins': 280,\n",
       " 'heart': 281,\n",
       " 'thought': 282,\n",
       " '6': 283,\n",
       " 'holiday': 284,\n",
       " 'lunch': 285,\n",
       " 'live': 286,\n",
       " 'man': 287,\n",
       " 'best': 288,\n",
       " 'talk': 289,\n",
       " 'stuff': 290,\n",
       " 'class': 291,\n",
       " 'y': 292,\n",
       " 'smile': 293,\n",
       " \"didn't\": 294,\n",
       " 'draw': 295,\n",
       " 'few': 296,\n",
       " 'cs': 297,\n",
       " 'days': 298,\n",
       " '7': 299,\n",
       " 'being': 300,\n",
       " 'yup': 301,\n",
       " 'trying': 302,\n",
       " 'bit': 303,\n",
       " 'never': 304,\n",
       " 'meeting': 305,\n",
       " 'thats': 306,\n",
       " 'job': 307,\n",
       " 'better': 308,\n",
       " 'house': 309,\n",
       " 'line': 310,\n",
       " 'finish': 311,\n",
       " 'cool': 312,\n",
       " 'long': 313,\n",
       " 'ill': 314,\n",
       " 'ready': 315,\n",
       " 'person': 316,\n",
       " 'having': 317,\n",
       " 'car': 318,\n",
       " 'mind': 319,\n",
       " 'end': 320,\n",
       " 'enjoy': 321,\n",
       " 'ã¥â£1': 322,\n",
       " 'latest': 323,\n",
       " 'half': 324,\n",
       " 'play': 325,\n",
       " 'check': 326,\n",
       " 'real': 327,\n",
       " 'yo': 328,\n",
       " 'wk': 329,\n",
       " 'account': 330,\n",
       " 'because': 331,\n",
       " 'dat': 332,\n",
       " 'than': 333,\n",
       " 'chance': 334,\n",
       " 'god': 335,\n",
       " 'lar': 336,\n",
       " 'receive': 337,\n",
       " 'word': 338,\n",
       " 'camera': 339,\n",
       " 'eat': 340,\n",
       " 'awarded': 341,\n",
       " 'wanna': 342,\n",
       " 'nothing': 343,\n",
       " 'guess': 344,\n",
       " 'lot': 345,\n",
       " 'sir': 346,\n",
       " 'problem': 347,\n",
       " '1st': 348,\n",
       " 'world': 349,\n",
       " 'another': 350,\n",
       " 'liao': 351,\n",
       " 'big': 352,\n",
       " 'dinner': 353,\n",
       " 'month': 354,\n",
       " 'ah': 355,\n",
       " 'birthday': 356,\n",
       " 'shows': 357,\n",
       " 'guys': 358,\n",
       " 'start': 359,\n",
       " 'into': 360,\n",
       " 'shit': 361,\n",
       " 'sweet': 362,\n",
       " 'ã¥â£1000': 363,\n",
       " 'girl': 364,\n",
       " 'luv': 365,\n",
       " 'jus': 366,\n",
       " 'might': 367,\n",
       " 'box': 368,\n",
       " 'ever': 369,\n",
       " 'quite': 370,\n",
       " 'cost': 371,\n",
       " 'watching': 372,\n",
       " 'room': 373,\n",
       " '150ppm': 374,\n",
       " 'landline': 375,\n",
       " 'bt': 376,\n",
       " 'offer': 377,\n",
       " 'video': 378,\n",
       " 'early': 379,\n",
       " 'xxx': 380,\n",
       " 'speak': 381,\n",
       " 'once': 382,\n",
       " 'aight': 383,\n",
       " 'tv': 384,\n",
       " 'called': 385,\n",
       " 'watch': 386,\n",
       " 'probably': 387,\n",
       " 'rate': 388,\n",
       " 'apply': 389,\n",
       " 'wont': 390,\n",
       " 'remember': 391,\n",
       " 'does': 392,\n",
       " 'maybe': 393,\n",
       " 'hear': 394,\n",
       " 'pa': 395,\n",
       " 'bed': 396,\n",
       " 'forgot': 397,\n",
       " 'll': 398,\n",
       " 'boy': 399,\n",
       " 'po': 400,\n",
       " 'thanx': 401,\n",
       " 'plan': 402,\n",
       " 'shall': 403,\n",
       " 'two': 404,\n",
       " 'minutes': 405,\n",
       " 'sat': 406,\n",
       " 'actually': 407,\n",
       " 'den': 408,\n",
       " 'bad': 409,\n",
       " 'princess': 410,\n",
       " 'fun': 411,\n",
       " '9': 412,\n",
       " 'code': 413,\n",
       " 'pay': 414,\n",
       " 'left': 415,\n",
       " 'ringtone': 416,\n",
       " 'look': 417,\n",
       " 'weekend': 418,\n",
       " 'part': 419,\n",
       " 'between': 420,\n",
       " 'easy': 421,\n",
       " 'reach': 422,\n",
       " 'shopping': 423,\n",
       " 'baby': 424,\n",
       " 'dunno': 425,\n",
       " 'orange': 426,\n",
       " 'office': 427,\n",
       " 'kiss': 428,\n",
       " '2nd': 429,\n",
       " \"he's\": 430,\n",
       " 'dis': 431,\n",
       " '10': 432,\n",
       " 'little': 433,\n",
       " 'leh': 434,\n",
       " 'face': 435,\n",
       " 'didnt': 436,\n",
       " 'hour': 437,\n",
       " 'network': 438,\n",
       " 'selected': 439,\n",
       " 'enough': 440,\n",
       " '000': 441,\n",
       " 'thank': 442,\n",
       " 'bus': 443,\n",
       " \"how's\": 444,\n",
       " 'looking': 445,\n",
       " 'anyway': 446,\n",
       " 'award': 447,\n",
       " 'those': 448,\n",
       " 'm': 449,\n",
       " 'working': 450,\n",
       " 'everything': 451,\n",
       " 'made': 452,\n",
       " 'put': 453,\n",
       " 'wife': 454,\n",
       " 'most': 455,\n",
       " 'afternoon': 456,\n",
       " 'without': 457,\n",
       " 'missing': 458,\n",
       " 'tmr': 459,\n",
       " 'evening': 460,\n",
       " 'collect': 461,\n",
       " 'asked': 462,\n",
       " 'texts': 463,\n",
       " '8': 464,\n",
       " 'while': 465,\n",
       " 'fuck': 466,\n",
       " 'dad': 467,\n",
       " 'town': 468,\n",
       " 'until': 469,\n",
       " 'wif': 470,\n",
       " 'though': 471,\n",
       " \"there's\": 472,\n",
       " 'calls': 473,\n",
       " 'since': 474,\n",
       " 'came': 475,\n",
       " 'okay': 476,\n",
       " 'says': 477,\n",
       " 'must': 478,\n",
       " 'school': 479,\n",
       " 'join': 480,\n",
       " 'mail': 481,\n",
       " 'sexy': 482,\n",
       " 'xmas': 483,\n",
       " 'true': 484,\n",
       " 'details': 485,\n",
       " 'entry': 486,\n",
       " 'goes': 487,\n",
       " 'update': 488,\n",
       " 'wanted': 489,\n",
       " 'pain': 490,\n",
       " 'means': 491,\n",
       " 'abt': 492,\n",
       " 'able': 493,\n",
       " 'hav': 494,\n",
       " 'important': 495,\n",
       " 'g': 496,\n",
       " 'wake': 497,\n",
       " 'tones': 498,\n",
       " 'wot': 499,\n",
       " 'bring': 500,\n",
       " 'collection': 501,\n",
       " 'times': 502,\n",
       " 'messages': 503,\n",
       " 'missed': 504,\n",
       " 'mob': 505,\n",
       " 'show': 506,\n",
       " 'price': 507,\n",
       " 'juz': 508,\n",
       " 'years': 509,\n",
       " 'decimal': 510,\n",
       " 'plz': 511,\n",
       " 'de': 512,\n",
       " 'away': 513,\n",
       " 'gift': 514,\n",
       " 'plus': 515,\n",
       " 'valid': 516,\n",
       " 'ã¥â£100': 517,\n",
       " 'alright': 518,\n",
       " 'till': 519,\n",
       " 're': 520,\n",
       " 'saw': 521,\n",
       " 'yesterday': 522,\n",
       " 'hair': 523,\n",
       " 'wen': 524,\n",
       " 'havent': 525,\n",
       " 'else': 526,\n",
       " 'worry': 527,\n",
       " '500': 528,\n",
       " '10p': 529,\n",
       " 'music': 530,\n",
       " 'weekly': 531,\n",
       " 'attempt': 532,\n",
       " 'guy': 533,\n",
       " 'colour': 534,\n",
       " 'net': 535,\n",
       " 'words': 536,\n",
       " 'yours': 537,\n",
       " 'double': 538,\n",
       " 'run': 539,\n",
       " 'making': 540,\n",
       " 'food': 541,\n",
       " 'haf': 542,\n",
       " 'til': 543,\n",
       " 'id': 544,\n",
       " 'oso': 545,\n",
       " 'shop': 546,\n",
       " 'book': 547,\n",
       " 'dude': 548,\n",
       " 'stay': 549,\n",
       " 'bored': 550,\n",
       " 'online': 551,\n",
       " 'makes': 552,\n",
       " 'lei': 553,\n",
       " 'question': 554,\n",
       " 'national': 555,\n",
       " 'ard': 556,\n",
       " \"we're\": 557,\n",
       " \"won't\": 558,\n",
       " 'tried': 559,\n",
       " 'delivery': 560,\n",
       " 'yourself': 561,\n",
       " \"haven't\": 562,\n",
       " 'driving': 563,\n",
       " 'test': 564,\n",
       " 'address': 565,\n",
       " 'answer': 566,\n",
       " 'top': 567,\n",
       " 'coz': 568,\n",
       " \"what's\": 569,\n",
       " 'nite': 570,\n",
       " 'hot': 571,\n",
       " 'hurt': 572,\n",
       " 'friendship': 573,\n",
       " 'change': 574,\n",
       " 'feeling': 575,\n",
       " 'either': 576,\n",
       " 'these': 577,\n",
       " 'sch': 578,\n",
       " 'family': 579,\n",
       " 'goin': 580,\n",
       " 'hours': 581,\n",
       " 'date': 582,\n",
       " 'http': 583,\n",
       " 'bonus': 584,\n",
       " 'trip': 585,\n",
       " 'comes': 586,\n",
       " 'ã¥â£5000': 587,\n",
       " 'movie': 588,\n",
       " 'busy': 589,\n",
       " \"''\": 590,\n",
       " 'todays': 591,\n",
       " 'order': 592,\n",
       " 'believe': 593,\n",
       " 'both': 594,\n",
       " 'vouchers': 595,\n",
       " 'wid': 596,\n",
       " 'full': 597,\n",
       " 'calling': 598,\n",
       " 'tot': 599,\n",
       " 'beautiful': 600,\n",
       " 'sae': 601,\n",
       " 'lose': 602,\n",
       " 'game': 603,\n",
       " 'together': 604,\n",
       " 'wants': 605,\n",
       " '8007': 606,\n",
       " 'sad': 607,\n",
       " 'set': 608,\n",
       " 'smiling': 609,\n",
       " 'mean': 610,\n",
       " 'old': 611,\n",
       " 'points': 612,\n",
       " 'ã¥â£2000': 613,\n",
       " 'leaving': 614,\n",
       " 'story': 615,\n",
       " 'sleeping': 616,\n",
       " 'noe': 617,\n",
       " 'happen': 618,\n",
       " 'ring': 619,\n",
       " 'club': 620,\n",
       " 'charge': 621,\n",
       " 'games': 622,\n",
       " \"we'll\": 623,\n",
       " 'chikku': 624,\n",
       " 'huh': 625,\n",
       " 'eve': 626,\n",
       " 'ã¥â£500': 627,\n",
       " 'saying': 628,\n",
       " 'drive': 629,\n",
       " 'await': 630,\n",
       " 'dreams': 631,\n",
       " 'brother': 632,\n",
       " 'pounds': 633,\n",
       " 'news': 634,\n",
       " 'aft': 635,\n",
       " 'tomo': 636,\n",
       " 'congrats': 637,\n",
       " 'took': 638,\n",
       " 'finished': 639,\n",
       " 'started': 640,\n",
       " 'private': 641,\n",
       " 'gr8': 642,\n",
       " 'awesome': 643,\n",
       " 'minute': 644,\n",
       " 'walk': 645,\n",
       " '86688': 646,\n",
       " 'okie': 647,\n",
       " 'post': 648,\n",
       " 'row': 649,\n",
       " 'poly': 650,\n",
       " 'pm': 651,\n",
       " 'thinking': 652,\n",
       " 'pics': 653,\n",
       " 'email': 654,\n",
       " 'rite': 655,\n",
       " 'pic': 656,\n",
       " 'available': 657,\n",
       " 'final': 658,\n",
       " \"c's\": 659,\n",
       " 'tho': 660,\n",
       " 'forget': 661,\n",
       " 'second': 662,\n",
       " 'close': 663,\n",
       " 'cause': 664,\n",
       " 'services': 665,\n",
       " 'taking': 666,\n",
       " 'everyone': 667,\n",
       " 'wil': 668,\n",
       " 'angry': 669,\n",
       " '750': 670,\n",
       " 'unsubscribe': 671,\n",
       " 'lets': 672,\n",
       " 'drink': 673,\n",
       " 'head': 674,\n",
       " 'land': 675,\n",
       " 'gd': 676,\n",
       " 'neva': 677,\n",
       " 'pub': 678,\n",
       " \"she's\": 679,\n",
       " 'drop': 680,\n",
       " 'auction': 681,\n",
       " '11': 682,\n",
       " 'lesson': 683,\n",
       " 'lucky': 684,\n",
       " 'xx': 685,\n",
       " 'search': 686,\n",
       " '12hrs': 687,\n",
       " 'statement': 688,\n",
       " 'expires': 689,\n",
       " 'msgs': 690,\n",
       " 'open': 691,\n",
       " 'whats': 692,\n",
       " 'lots': 693,\n",
       " 'each': 694,\n",
       " 'smoke': 695,\n",
       " 'worth': 696,\n",
       " 'sis': 697,\n",
       " 'touch': 698,\n",
       " 'found': 699,\n",
       " 'break': 700,\n",
       " 'sounds': 701,\n",
       " 'company': 702,\n",
       " 'choose': 703,\n",
       " 'card': 704,\n",
       " 'w': 705,\n",
       " 'sister': 706,\n",
       " 'dating': 707,\n",
       " 'opt': 708,\n",
       " 'simple': 709,\n",
       " 'mine': 710,\n",
       " 'whatever': 711,\n",
       " 'voucher': 712,\n",
       " 'knw': 713,\n",
       " 'anyone': 714,\n",
       " 'don': 715,\n",
       " 'loving': 716,\n",
       " 'alone': 717,\n",
       " 'treat': 718,\n",
       " 'winner': 719,\n",
       " '100': 720,\n",
       " 'info': 721,\n",
       " 'pobox': 722,\n",
       " 'ha': 723,\n",
       " 'smth': 724,\n",
       " 'saturday': 725,\n",
       " 'decided': 726,\n",
       " '08000930705': 727,\n",
       " 'girls': 728,\n",
       " 'prob': 729,\n",
       " 'gone': 730,\n",
       " 'happened': 731,\n",
       " 'identifier': 732,\n",
       " 'nt': 733,\n",
       " 'type': 734,\n",
       " 'ltd': 735,\n",
       " 'hard': 736,\n",
       " 'frnd': 737,\n",
       " 'needs': 738,\n",
       " 'carlos': 739,\n",
       " 'boytoy': 740,\n",
       " 'college': 741,\n",
       " 'takes': 742,\n",
       " 'anytime': 743,\n",
       " 'far': 744,\n",
       " 'mobileupd8': 745,\n",
       " 'kind': 746,\n",
       " 'visit': 747,\n",
       " 'fast': 748,\n",
       " 'mum': 749,\n",
       " 'sun': 750,\n",
       " 'crazy': 751,\n",
       " 'wonderful': 752,\n",
       " \"doesn't\": 753,\n",
       " 'camcorder': 754,\n",
       " 'used': 755,\n",
       " 'hit': 756,\n",
       " 'operator': 757,\n",
       " 'friday': 758,\n",
       " 'quiz': 759,\n",
       " 'player': 760,\n",
       " 'parents': 761,\n",
       " 'hand': 762,\n",
       " 'content': 763,\n",
       " 'wit': 764,\n",
       " \"you've\": 765,\n",
       " 'finally': 766,\n",
       " 'darlin': 767,\n",
       " 'rs': 768,\n",
       " 'goodmorning': 769,\n",
       " 'oredi': 770,\n",
       " 'secret': 771,\n",
       " 'tel': 772,\n",
       " 'congratulations': 773,\n",
       " 'read': 774,\n",
       " 'light': 775,\n",
       " 'suite342': 776,\n",
       " '2lands': 777,\n",
       " '08000839402': 778,\n",
       " 'bout': 779,\n",
       " 'fucking': 780,\n",
       " 'nope': 781,\n",
       " 'outside': 782,\n",
       " 'fri': 783,\n",
       " 'ã¥â£3': 784,\n",
       " 'pretty': 785,\n",
       " 'sea': 786,\n",
       " 'o': 787,\n",
       " 'weeks': 788,\n",
       " 'â\\x80°ã\\x9b': 789,\n",
       " 'lovely': 790,\n",
       " 'mates': 791,\n",
       " 'wrong': 792,\n",
       " 'chennai': 793,\n",
       " 'hows': 794,\n",
       " '30': 795,\n",
       " 'wkly': 796,\n",
       " 'freemsg': 797,\n",
       " \"'\": 798,\n",
       " 'sunday': 799,\n",
       " 'credit': 800,\n",
       " 'hungry': 801,\n",
       " 'seeing': 802,\n",
       " 'telling': 803,\n",
       " 'whole': 804,\n",
       " 'frnds': 805,\n",
       " 'hmm': 806,\n",
       " 'mu': 807,\n",
       " \"you'll\": 808,\n",
       " 'yr': 809,\n",
       " 'their': 810,\n",
       " 'ni8': 811,\n",
       " 'f': 812,\n",
       " 'fancy': 813,\n",
       " 'bank': 814,\n",
       " 'log': 815,\n",
       " 'course': 816,\n",
       " 'tc': 817,\n",
       " 'thinks': 818,\n",
       " 'case': 819,\n",
       " 'meant': 820,\n",
       " 'hold': 821,\n",
       " 'unlimited': 822,\n",
       " 'blue': 823,\n",
       " 'fone': 824,\n",
       " 'project': 825,\n",
       " 'reason': 826,\n",
       " 'ã¥â£250': 827,\n",
       " 'ten': 828,\n",
       " 'welcome': 829,\n",
       " 'cum': 830,\n",
       " 'frm': 831,\n",
       " 'savamob': 832,\n",
       " 'offers': 833,\n",
       " 'listen': 834,\n",
       " 'snow': 835,\n",
       " 'b4': 836,\n",
       " 'mate': 837,\n",
       " 'least': 838,\n",
       " 'earlier': 839,\n",
       " 'party': 840,\n",
       " 'point': 841,\n",
       " 'press': 842,\n",
       " 'valued': 843,\n",
       " 'almost': 844,\n",
       " 'etc': 845,\n",
       " 'cut': 846,\n",
       " 'hee': 847,\n",
       " 'download': 848,\n",
       " '0800': 849,\n",
       " 'mah': 850,\n",
       " 'felt': 851,\n",
       " 'caller': 852,\n",
       " '03': 853,\n",
       " 'numbers': 854,\n",
       " 'age': 855,\n",
       " 'tired': 856,\n",
       " 'hmmm': 857,\n",
       " 'mr': 858,\n",
       " 'mrng': 859,\n",
       " 'balance': 860,\n",
       " 'march': 861,\n",
       " 'side': 862,\n",
       " 'fr': 863,\n",
       " '87066': 864,\n",
       " 'dnt': 865,\n",
       " 'stupid': 866,\n",
       " 'bslvyl': 867,\n",
       " 'lost': 868,\n",
       " 'christmas': 869,\n",
       " 'reading': 870,\n",
       " 'txts': 871,\n",
       " 'ago': 872,\n",
       " 'currently': 873,\n",
       " 'motorola': 874,\n",
       " 'talking': 875,\n",
       " 'couple': 876,\n",
       " 'phones': 877,\n",
       " 'ass': 878,\n",
       " 'india': 879,\n",
       " 'park': 880,\n",
       " 'ã¥â£2': 881,\n",
       " 'within': 882,\n",
       " '2003': 883,\n",
       " '800': 884,\n",
       " 'un': 885,\n",
       " 'yar': 886,\n",
       " 'happiness': 887,\n",
       " 'area': 888,\n",
       " 'ã¥â£350': 889,\n",
       " 'sex': 890,\n",
       " 'mayb': 891,\n",
       " 'understand': 892,\n",
       " 'support': 893,\n",
       " 'na': 894,\n",
       " 'luck': 895,\n",
       " 'enter': 896,\n",
       " 'gas': 897,\n",
       " 'father': 898,\n",
       " 'comp': 899,\n",
       " \"i'd\": 900,\n",
       " 'mobiles': 901,\n",
       " '20': 902,\n",
       " 'eh': 903,\n",
       " 'charged': 904,\n",
       " 'confirm': 905,\n",
       " 'wow': 906,\n",
       " 'ac': 907,\n",
       " 'red': 908,\n",
       " 'correct': 909,\n",
       " 'pass': 910,\n",
       " 'song': 911,\n",
       " 'complimentary': 912,\n",
       " 'gotta': 913,\n",
       " 'computer': 914,\n",
       " 'mom': 915,\n",
       " 'askd': 916,\n",
       " 'invited': 917,\n",
       " 'uncle': 918,\n",
       " 'sending': 919,\n",
       " 'direct': 920,\n",
       " 'semester': 921,\n",
       " 'reveal': 922,\n",
       " 'laptop': 923,\n",
       " 'questions': 924,\n",
       " 'swing': 925,\n",
       " 'ends': 926,\n",
       " 'die': 927,\n",
       " 'via': 928,\n",
       " 'met': 929,\n",
       " 'st': 930,\n",
       " 'call2optout': 931,\n",
       " 'seen': 932,\n",
       " 'rental': 933,\n",
       " 'th': 934,\n",
       " 'supposed': 935,\n",
       " 'ipod': 936,\n",
       " 'redeemed': 937,\n",
       " '04': 938,\n",
       " 'through': 939,\n",
       " 'gym': 940,\n",
       " 'darren': 941,\n",
       " 'ans': 942,\n",
       " 'picking': 943,\n",
       " 'ugh': 944,\n",
       " 'extra': 945,\n",
       " 'knew': 946,\n",
       " 'heard': 947,\n",
       " 'information': 948,\n",
       " 'surprise': 949,\n",
       " 'grins': 950,\n",
       " 'gal': 951,\n",
       " 'difficult': 952,\n",
       " 'john': 953,\n",
       " \"wasn't\": 954,\n",
       " 'std': 955,\n",
       " 'usf': 956,\n",
       " 'reward': 957,\n",
       " '12': 958,\n",
       " 'wap': 959,\n",
       " 'eg': 960,\n",
       " 'comin': 961,\n",
       " 'abiola': 962,\n",
       " 'crave': 963,\n",
       " 'gets': 964,\n",
       " 'move': 965,\n",
       " 'checking': 966,\n",
       " 'rply': 967,\n",
       " 'loads': 968,\n",
       " 'shower': 969,\n",
       " \"isn't\": 970,\n",
       " 'entered': 971,\n",
       " 'match': 972,\n",
       " 'dogging': 973,\n",
       " 'txting': 974,\n",
       " 'lovable': 975,\n",
       " 'wine': 976,\n",
       " 'dream': 977,\n",
       " 'safe': 978,\n",
       " 'muz': 979,\n",
       " 'bath': 980,\n",
       " 'orchard': 981,\n",
       " 'kate': 982,\n",
       " 'exam': 983,\n",
       " 'bcoz': 984,\n",
       " 'own': 985,\n",
       " 'wana': 986,\n",
       " 'somebody': 987,\n",
       " 'rest': 988,\n",
       " 'plans': 989,\n",
       " 'small': 990,\n",
       " 'jay': 991,\n",
       " 'ex': 992,\n",
       " 'hg': 993,\n",
       " 'w1j6hl': 994,\n",
       " 'discount': 995,\n",
       " 'slow': 996,\n",
       " 'rock': 997,\n",
       " 'asking': 998,\n",
       " 'remove': 999,\n",
       " 'monday': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx,valx,trainy,valy = train_test_split(data[\"text\"],target)\n",
    "\n",
    "trainx = sequence.pad_sequences(token.texts_to_sequences(trainx),maxlen=70)\n",
    "valx = sequence.pad_sequences(token.texts_to_sequences(valx),maxlen=70)\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index)+1,300))\n",
    "for word,i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classfier,feature_vector_train, label, feature_vector_val,valid_y):\n",
    "    classifier.fit(feature_vector_train,label)\n",
    "    predictions = classfier.predict(feature_vector_val)\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    return accuracy_score(predictions,valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers\n",
    "\n",
    "def create_cnn():\n",
    "    input_layer = layers.Input((70,))\n",
    "    embedding_layer = layers.Embedding(len(word_index)+1,300,weights = [embedding_matrix],trainable=False)(input_layer)\n",
    "    conv_layer = layers.Convolution1D(100,3,activation='relu')(embedding_layer)\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "    output_layer = layers.Dense(50,activation='relu')(pooling_layer)\n",
    "    output_layer = layers.Dropout(.25)(output_layer)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid')(output_layer)\n",
    "    \n",
    "    model = models.Model(inputs = input_layer,outputs = output_layer)\n",
    "    model.compile(optimizer=optimizers.Adam(),loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4179/4179 [==============================] - 1s 212us/step - loss: 0.1620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8765254845656856"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(classifier,trainx,trainy,valx,valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
